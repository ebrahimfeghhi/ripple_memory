{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import sys \n",
    "sys.path.append('/home1/efeghhi/ripple_memory/analysis_code/')\n",
    "from load_data import *\n",
    "from analyze_data import *\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def permute_amplitude_time_series(amplitude_time_series):\n",
    "    \n",
    "     \n",
    "    '''\n",
    "    ndarray amplitude_time_series: array containing amplitude values over a given trial \n",
    "    \n",
    "    Circular permutes the input vector. \n",
    "    '''\n",
    "    \n",
    "    # Get the length of the time series\n",
    "    series_length = len(amplitude_time_series)\n",
    "    \n",
    "    min_cut_index = int(0.1 * series_length)\n",
    "    max_cut_index = int(0.9 * series_length )\n",
    "\n",
    "    # Choose a random index to cut the time series\n",
    "    cut_index = np.random.randint(min_cut_index, max_cut_index)\n",
    "\n",
    "    # Create the permuted time series by reversing the order of both parts\n",
    "    permuted_series = np.concatenate((amplitude_time_series[cut_index:], amplitude_time_series[:cut_index]))\n",
    "\n",
    "    return permuted_series\n",
    "\n",
    "def compute_gamma_theta_dist(pd):\n",
    "    \n",
    "    '''\n",
    "    dataframe pd: contains theta phase, low gamma, and high gamma values for a single trial\n",
    "    \n",
    "    This function groups high and low gamma values by theta phase to create a histogram. \n",
    "    It then normalizes this histogram such that the bins sum to 1.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    low_gammas_by_theta = []\n",
    "    high_gammas_by_theta = []\n",
    "    \n",
    "    for theta_phase in np.unique(pd.theta):\n",
    "        \n",
    "        tp = pd.loc[pd.theta==theta_phase]\n",
    "        low_gammas_by_theta.append(np.mean(tp.lg))\n",
    "        high_gammas_by_theta.append(np.mean(tp.hg))\n",
    "        \n",
    "    lg_pdist = np.array(low_gammas_by_theta)/np.sum(low_gammas_by_theta)\n",
    "    hg_pdist = np.array(high_gammas_by_theta)/np.sum(high_gammas_by_theta)\n",
    "    \n",
    "    return lg_pdist, hg_pdist\n",
    "\n",
    "def compute_entropy(probability_arr):\n",
    "    \n",
    "    '''\n",
    "    ndarray probability_arr: 1 or 2d probability array\n",
    "    \n",
    "    If 1d array, returns entropy of the probability distribution.\n",
    "    If 2d array, returns entr\n",
    "    '''\n",
    "    \n",
    "    import math\n",
    "\n",
    "    if len(probability_arr.shape)==1:\n",
    "        entropy = -np.sum(probability_arr*np.log(probability_arr))\n",
    "    else:\n",
    "        # sum across bins (which are along the second axis) for permuted data\n",
    "        entropy = -np.sum(probability_arr*np.log(probability_arr), axis=1)\n",
    "    return entropy\n",
    "\n",
    "def compute_MI(dist, n_bins):\n",
    "    \n",
    "    '''\n",
    "    ndarray dist: probability distribution of gamma amplitudes grouped by theta phase.\n",
    "    For permutated data dist is of shape num_permutations x n_bins\n",
    "    int n_bins: number of theta phase bins used\n",
    "    \n",
    "    Computes modulation index, which is the entropy of the provided \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    uniform_entropy = np.log(n_bins)\n",
    "    entropy_vals = compute_entropy(dist)\n",
    "    \n",
    "    MI = (uniform_entropy - entropy_vals)/uniform_entropy\n",
    "    return MI\n",
    "\n",
    "\n",
    "def compute_p_value(dat, dat_permuted):\n",
    "    \n",
    "    '''\n",
    "    :param float dat: values from real data\n",
    "    :param ndarray dat_permuted: permuted data\n",
    "    \n",
    "    Returns one-side p-value testing the hypothesis that the real\n",
    "    data value is larger than the permuted distribution.\n",
    "    '''\n",
    "    \n",
    "    # 1) find the number of permuted values the real data is larger than \n",
    "    # 2) divide this by the number of permuted values \n",
    "    # 3) Subtract by 1 to get p value\n",
    "    p_value = 1 - np.argwhere(dat > dat_permuted).shape[0]/dat_permuted.shape[0]\n",
    "    return p_value\n",
    "\n",
    "\n",
    "# load data \n",
    "def load_pac_pd(encoding_mode, roi_mode):\n",
    "    \n",
    "    '''\n",
    "    :param int encoding_mode: 0 for recall, 1 for encoding \n",
    "\n",
    "    :param int roi_mode: 0 for short, 1 for medium, 2 for long.\n",
    "    '''\n",
    "    \n",
    "    if roi_mode == 0:\n",
    "        enc_start_roi = 400\n",
    "        enc_end_roi = 1100\n",
    "        rec_start_roi = -600\n",
    "        rec_end_roi = -100\n",
    "        \n",
    "    if roi_mode == 1:\n",
    "        print(\"Loading 1 second data\")\n",
    "        enc_start_roi = 300\n",
    "        enc_end_roi = 1300\n",
    "        rec_start_roi = -1100\n",
    "        rec_end_roi = -100\n",
    "    \n",
    "    if roi_mode == 2: \n",
    "        enc_start_roi = 100\n",
    "        enc_end_roi = 1700\n",
    "        rec_start_roi = -1600\n",
    "        rec_end = -100\n",
    "\n",
    "    sr = 500 # sampling rate in Hz\n",
    "    sr_factor = 1000/sr \n",
    "    \n",
    "    if encoding_mode:\n",
    "        # for encoding trials, neural recording \n",
    "        # starts from -700 ms before word onset \n",
    "        # and finishes 2300 ms post word onset \n",
    "        start_time = -700\n",
    "        end_time = 2300\n",
    "\n",
    "        # timepoints of interest\n",
    "        start_roi = enc_start_roi\n",
    "        end_roi = enc_end_roi\n",
    "\n",
    "    else:\n",
    "        # for recall trials, neural recording \n",
    "        # starts from -1000 ms before word onset \n",
    "        # and finishes 1000 ms post word onset \n",
    "        start_time = -2000\n",
    "        end_time = 2000\n",
    "        \n",
    "        # this is where we are interested in analyzing \n",
    "        # -600 to -100 ms (0 ms is word onset)\n",
    "        start_roi = rec_start_roi\n",
    "        end_roi = rec_end_roi\n",
    "\n",
    "    # convert to indices based on start time and sampling rate factor\n",
    "    start_idx = int((start_roi - start_time)/sr_factor)\n",
    "    end_idx = int((end_roi-start_time)/sr_factor)\n",
    "\n",
    "    \n",
    "    if encoding_mode:\n",
    "        dd_trials = np.load('/home1/efeghhi/ripple_memory/analysis_code/pac_analyses/updated_data/dd_trials_encoding.npz')\n",
    "    else:\n",
    "        dd_trials = np.load('/home1/efeghhi/ripple_memory/analysis_code/pac_analyses/updated_data/dd_trials_recall.npz')\n",
    "\n",
    "    # corresponds to 400 - 1100 ms post word onset if encoding\n",
    "    # or -600 to -100 ms before word recall if recalled \n",
    "    start_time = start_roi\n",
    "    end_time = end_roi\n",
    "    num_time_points = end_time - start_time\n",
    "    num_trials = len(dd_trials['theta'])\n",
    "    n_bins = 18 # number of bins for theta phase \n",
    "        \n",
    "    selected_idxs = np.ones(num_trials,  dtype=bool)\n",
    "    \n",
    "    # discretize theta phase to take on integer values from 0 to 18\n",
    "    theta_binned = np.ravel(np.floor(((dd_trials['theta'][:, start_time:end_time] + np.pi)/(2*np.pi))*n_bins))\n",
    "    high_gamma_raveled = np.ravel(dd_trials['high_gamma'][:, start_time:end_time])\n",
    "    low_gamma_raveled = np.ravel(dd_trials['low_gamma'][:, start_time:end_time])\n",
    "    trial_number = np.repeat(np.arange(num_trials), num_time_points)\n",
    "    clustered = np.repeat(dd_trials['clust_int'][selected_idxs], num_time_points)\n",
    "    subj_ravel = np.repeat(dd_trials['subj'][selected_idxs], num_time_points)\n",
    "    elec_ravel = np.repeat(dd_trials['elec_labels'][selected_idxs], num_time_points)\n",
    "    \n",
    "    if encoding_mode: \n",
    "        correct = np.repeat(dd_trials['correct'][selected_idxs], num_time_points)\n",
    "    else:\n",
    "        # if using recalled data, just fill all trials with correct set to -1\n",
    "        # since there is no correct key\n",
    "        correct = -1*np.ones_like(clustered)\n",
    "        \n",
    "   \n",
    "    regression_pd = pd.DataFrame({'theta':theta_binned, 'high_gamma': high_gamma_raveled,'low_gamma':low_gamma_raveled, \n",
    "                        'correct': correct, 'clust': clustered, 'subj': subj_ravel, 'trial_num': trial_number, \n",
    "                                 'elec_labels': elec_ravel})\n",
    "\n",
    "    return regression_pd, n_bins, num_time_points\n",
    "\n",
    "def compute_gamma_theta_dist(pd):\n",
    "    \n",
    "    low_gammas_by_theta = []\n",
    "    high_gammas_by_theta = []\n",
    "    \n",
    "    for theta_phase in np.unique(pd.theta):\n",
    "        \n",
    "        tp = pd.loc[pd.theta==theta_phase]\n",
    "        low_gammas_by_theta.append(np.mean(tp.lg))\n",
    "        high_gammas_by_theta.append(np.mean(tp.hg))\n",
    "        \n",
    "    lg_pdist = np.array(low_gammas_by_theta)/np.sum(low_gammas_by_theta)\n",
    "    hg_pdist = np.array(high_gammas_by_theta)/np.sum(high_gammas_by_theta)\n",
    "    \n",
    "    return lg_pdist, hg_pdist\n",
    "        \n",
    "def compute_theta_gamma_PAC(single_subject, num_time_points, n_bins,\n",
    "                            num_permutations=3):\n",
    "    \n",
    "    num_trials_subj = np.unique(single_subject.trial_num).shape[0]\n",
    "    stored_dist_lg = np.zeros((num_trials_subj, n_bins))\n",
    "    stored_dist_permutations_lg = np.zeros((num_trials_subj, num_permutations, n_bins))\n",
    "    stored_dist_hg = np.zeros((num_trials_subj, n_bins))\n",
    "    stored_dist_permutations_hg = np.zeros((num_trials_subj, num_permutations, n_bins))\n",
    "\n",
    "    for idx, trial_num in enumerate(np.unique(single_subject.trial_num)):\n",
    "        \n",
    "        if idx % 20 == 0:\n",
    "            print(f\"Trial {idx} out {np.unique(single_subject.trial_num).shape[0]}\")\n",
    "\n",
    "        trial_pd = single_subject.loc[single_subject.trial_num == trial_num]\n",
    "\n",
    "        original_pd = pd.DataFrame({'lg': trial_pd.low_gamma, 'hg': trial_pd.high_gamma, \n",
    "                                    'theta': trial_pd.theta})\n",
    "\n",
    "        # returns nbins shape array,\n",
    "        # where each entry is the gamma (low or high) \"probability\"\n",
    "        # at a given theta phase bin\n",
    "        lg_dist, hg_dist = compute_gamma_theta_dist(original_pd)\n",
    "\n",
    "        # store gamma distributions by theta phase for each trial \n",
    "        stored_dist_lg[idx] = lg_dist\n",
    "        stored_dist_hg[idx] = hg_dist\n",
    "\n",
    "        # for each trial, also compute a distribution when permuting the gamma \n",
    "        # arrays\n",
    "        for n in range(num_permutations):\n",
    "\n",
    "            low_gamma_permuted = permute_amplitude_time_series(trial_pd.low_gamma)\n",
    "            high_gamma_permuted = permute_amplitude_time_series(trial_pd.high_gamma)\n",
    "\n",
    "\n",
    "            permuted_pd = pd.DataFrame({'lg':low_gamma_permuted, 'hg':high_gamma_permuted, \n",
    "                                        'theta':trial_pd.theta})\n",
    "\n",
    "            lg_dist_p, hg_dist_p = compute_gamma_theta_dist(permuted_pd)\n",
    "\n",
    "            stored_dist_permutations_lg[idx, n] = lg_dist_p\n",
    "            stored_dist_permutations_hg[idx, n] = hg_dist_p\n",
    "\n",
    "    return stored_dist_lg, stored_dist_hg, stored_dist_permutations_lg, stored_dist_permutations_hg\n",
    "\n",
    "def finished_subjects(mode, metric, \n",
    "                      savePath = '/home1/efeghhi/ripple_memory/analysis_code/pac_analyses/saved_results/'):\n",
    "    \n",
    "    '''\n",
    "    :param int mode: not correct (0), correct (1), unclustered (2), clustered (3) \n",
    "    :param str: MOVI or MI\n",
    "    :param str savePath: folder where previous results are stored to \n",
    "    '''\n",
    "    \n",
    "    # just load hg, because the subjects are the same\n",
    "    results= dict(np.load(f\"{savePath}hg_{metric}_by_subj_{mode}.npz\"))\n",
    "    \n",
    "    subjects_ran = sorted(results.keys())\n",
    "    \n",
    "    return subjects_ran         \n",
    "            \n",
    "def save_JSD(theta_gamma_hist_encoding, theta_gamma_hist_recalled):\n",
    "         \n",
    "        stored_dist_lg_encoding = np.mean(theta_gamma_hist_encoding[0],axis=0)\n",
    "        stored_dist_hg_encoding = np.mean(theta_gamma_hist_encoding[1],axis=0)\n",
    "        stored_dist_permutations_lg_encoding = np.mean(theta_gamma_hist_encoding[2],axis=0)\n",
    "        stored_dist_permutations_hg_encoding = np.mean(theta_gamma_hist_encoding[3], axis=0)\n",
    "        \n",
    "        stored_dist_lg_recalled = np.mean(theta_gamma_hist_recalled[0],axis=0)\n",
    "        stored_dist_hg_recalled = np.mean(theta_gamma_hist_recalled[1],axis=0)\n",
    "        stored_dist_permutations_lg_recalled = np.mean(theta_gamma_hist_recalled[2],axis=0)\n",
    "        stored_dist_permutations_hg_recalled = np.mean(theta_gamma_hist_recalled[3],axis=0)\n",
    "        \n",
    "        print(stored_dist_lg_encoding.shape, stored_dist_permutations_lg_encoding.shape)\n",
    "        \n",
    "        jsd_lg = jensenshannon(stored_dist_lg_encoding, stored_dist_lg_recalled)\n",
    "        jsd_hg = jensenshannon(stored_dist_hg_encoding, stored_dist_hg_recalled)\n",
    "       \n",
    "        jsd_lg_permuted = jensenshannon(stored_dist_permutations_lg_encoding, \n",
    "                                        stored_dist_permutations_lg_recalled, axis=1)\n",
    "        \n",
    "        jsd_hg_permuted = jensenshannon(stored_dist_permutations_hg_encoding, \n",
    "                                        stored_dist_permutations_hg_recalled, axis=1)\n",
    "        \n",
    "        p_val_lg = compute_p_value(jsd_lg, jsd_lg_permuted)\n",
    "        p_val_hg = compute_p_value(jsd_hg, jsd_hg_permuted)\n",
    "        \n",
    "          \n",
    "        jsd_lg_z = (jsd_lg - np.mean(jsd_lg_permuted))/np.std(jsd_lg_permuted)\n",
    "        jsd_hg_z = (jsd_hg - np.mean(jsd_hg_permuted))/np.std(jsd_hg_permuted)\n",
    "        \n",
    "    \n",
    "        return jsd_lg, jsd_hg, p_val_lg, p_val_hg, jsd_lg_z, jsd_hg_z, jsd_lg_permuted, jsd_hg_permuted\n",
    "        \n",
    "        \n",
    "def save_MI(theta_gamma_hist, n_bins):\n",
    "    \n",
    "        stored_dist_lg = theta_gamma_hist[0]\n",
    "        stored_dist_hg = theta_gamma_hist[1]\n",
    "        stored_dist_permutations_lg = theta_gamma_hist[2]\n",
    "        stored_dist_permutations_hg = theta_gamma_hist[3]\n",
    "\n",
    "        # average aross distributions generated across trials for a given participant \n",
    "        # and compute MI\n",
    "        dist_lg = np.mean(stored_dist_lg, axis=0)\n",
    "        dist_hg = np.mean(stored_dist_hg, axis=0)\n",
    "\n",
    "        # average aross distributions generated across trials for a given participant \n",
    "        # and compute MI\n",
    "        MI_lg = compute_MI(np.mean(stored_dist_lg, axis=0), n_bins)\n",
    "        MI_hg = compute_MI(np.mean(stored_dist_hg, axis=0), n_bins)\n",
    "\n",
    "        # also do the same for permuted data. For permuted data, when we average across the trials \n",
    "        # the phase amplitude coupling should cancel out because each trial should be coupled to \n",
    "        # a distinct theta phase value because of the coupling. The resulting output will be of shape\n",
    "        # num_permutations. \n",
    "        MI_lg_p = compute_MI(np.mean(stored_dist_permutations_lg, axis=0), n_bins)\n",
    "        MI_hg_p = compute_MI(np.mean(stored_dist_permutations_hg, axis=0), n_bins)\n",
    "\n",
    "        # compute p-value as fraction of permuted MI values that are higher\n",
    "        # than or equal to the MI value obtained with the real data \n",
    "        p_val_lg = compute_p_value(MI_lg, MI_lg_p)\n",
    "        p_val_hg = compute_p_value(MI_hg, MI_hg_p)\n",
    "        \n",
    "        MI_lg_z = (MI_lg - np.mean(MI_lg_p))/np.std(MI_lg_p)\n",
    "        MI_hg_z = (MI_hg - np.mean(MI_hg_p))/np.std(MI_hg_p)\n",
    "        \n",
    "        return MI_lg, MI_hg, MI_lg_z, MI_hg_z, p_val_lg, p_val_hg, dist_lg, dist_hg\n",
    "    \n",
    "def save_MI_JSD(behav_mode, roi_mode,\n",
    "            savePath='/home1/efeghhi/ripple_memory/analysis_code/pac_analyses/saved_results/'):\n",
    "    \n",
    "    '''\n",
    "    :param int behav_mode: whether to analyze clustered (3) or unclustered (2) recalls\n",
    "    :param int roi_mode: 0 (short), 1 (1 sec), or 2 (1.5 sec) region of interest \n",
    "    :param str savePath: where to save MI and JSD values\n",
    "    '''\n",
    "    \n",
    "    bad_sessions = ['R1108J-2']\n",
    "    \n",
    "    # load neural and behavorial data for encoding and recall phases \n",
    "    dd_trials_encode = np.load('/home1/efeghhi/ripple_memory/analysis_code/pac_analyses/updated_data/dd_trials_encoding.npz')\n",
    "    dd_trials_recalled = np.load('/home1/efeghhi/ripple_memory/analysis_code/pac_analyses/updated_data/dd_trials_recall.npz')\n",
    "    \n",
    "    # process into a pd dataframe\n",
    "    pac_pd_encoding, n_bins, num_time_points_encoding = load_pac_pd(1, roi_mode)\n",
    "    pac_pd_recalled, _, num_time_points_recalled = load_pac_pd(0, roi_mode)\n",
    "    \n",
    "    # only interested in clust/unclust recalls for now, so analyzing\n",
    "    # only subsuquently recalled trials\n",
    "    pac_pd_encoding = pac_pd_encoding.loc[pac_pd_encoding.correct==1]\n",
    "    \n",
    "    # unclustered recalls\n",
    "    if behav_mode == 2:\n",
    "        pac_pd_encoding = pac_pd_encoding.loc[(pac_pd_encoding.clust==0)]\n",
    "        pac_pd_recalled = pac_pd_recalled.loc[pac_pd_recalled.clust==0]\n",
    "        \n",
    "    # clustered recall\n",
    "    if behav_mode == 3:\n",
    "        pac_pd_encoding = pac_pd_encoding.loc[pac_pd_encoding.clust==1]\n",
    "        pac_pd_recalled = pac_pd_recalled.loc[pac_pd_recalled.clust==1]\n",
    "    \n",
    "        \n",
    "    min_num_trials = 5\n",
    "    \n",
    "    store_MI_dict = {'MI_lg': [], 'MI_hg': [], 'MI_lg_z': [], \n",
    "                     'MI_hg_z': [], 'p_lg': [], 'p_hg': [], 'encoding': [], 'sub_sess_elec': [], \n",
    "                    'num_trials': []}\n",
    "    \n",
    "    store_JSD_dict = {'jsd_lg': [], 'jsd_hg': [],'jsd_lg_z': [], 'jsd_hg_z': [], 'p_lg': [], 'p_hg': [], \n",
    "                      'jsd_lg_permuted': [], 'jsd_hg_permuted': [], 'sub_sess_elec': [], \n",
    "                      'num_trials': []}\n",
    "    \n",
    "    store_theta_gamma_PAC_dist = {'lg_encode': [], 'hg_encode': [], 'lg_recall': [], 'hg_recall': []}\n",
    "    \n",
    "    # elec labels contains the subject, session number, and electrode name \n",
    "    # for each electrode \n",
    "    subj_sess_elec_encoding = np.unique(pac_pd_encoding['elec_labels'])\n",
    "    subj_sess_elec_recalled = np.unique(pac_pd_recalled['elec_labels'])\n",
    "    \n",
    "    shared_elec_labels = np.intersect1d(subj_sess_elec_encoding, subj_sess_elec_recalled) \n",
    "    \n",
    "    for sel in shared_elec_labels:\n",
    "        \n",
    "        if len([x for x in bad_sessions if x in sel]) > 0:\n",
    "            print(\"Skipping bad session\")\n",
    "            continue\n",
    "        \n",
    "        electrode_encoding = pac_pd_encoding.loc[pac_pd_encoding.elec_labels==sel]\n",
    "        electrode_recalled = pac_pd_recalled.loc[pac_pd_recalled.elec_labels==sel]\n",
    "\n",
    "        print(f\"Electrode: {sel}\")\n",
    "\n",
    "        num_trials_elec_encoding = int(electrode_encoding.high_gamma.shape[0]/num_time_points_encoding)\n",
    "        num_trials_elec_recalled = int(electrode_recalled.high_gamma.shape[0]/num_time_points_recalled)\n",
    "        \n",
    "        print(num_trials_elec_encoding, num_trials_elec_recalled)\n",
    "\n",
    "        # because we are only looking at recalled (clust/noclust) trials, \n",
    "        # the trial count should be identical \n",
    "        if num_trials_elec_encoding != num_trials_elec_recalled:\n",
    "            print(\"TRIAL COUNT IS WEIRD\")\n",
    "            print(sel)\n",
    "            print(num_trials_elec_encoding, num_trials_elec_recalled)\n",
    "            print(num_time_points_encoding, num_time_points_recalled)\n",
    "            continue\n",
    "\n",
    "        if min(num_trials_elec_encoding, num_trials_elec_recalled) < int(min_num_trials):\n",
    "            print(\"trial count too low, skipping elec\")\n",
    "            print(sel)\n",
    "            continue\n",
    "\n",
    "        print(\"ENCODING\")\n",
    "        theta_gamma_hist_encoding = compute_theta_gamma_PAC(electrode_encoding,\n",
    "                                                            num_time_points_encoding, n_bins)\n",
    "        print(\"RECALLED\")\n",
    "        theta_gamma_hist_recalled = compute_theta_gamma_PAC(electrode_recalled, \n",
    "                                                            num_time_points_recalled, n_bins)\n",
    "\n",
    "        MI_lg, MI_hg, MI_lg_z, MI_hg_z, p_val_lg, p_val_hg, dist_lg, dist_hg = save_MI(theta_gamma_hist_encoding, n_bins)\n",
    "\n",
    "        store_MI_dict['MI_lg'].append(MI_lg)\n",
    "        store_MI_dict['MI_hg'].append(MI_hg)\n",
    "        store_MI_dict['MI_lg_z'].append(MI_lg_z)\n",
    "        store_MI_dict['MI_hg_z'].append(MI_hg_z)\n",
    "        store_MI_dict['p_lg'].append(p_val_lg)\n",
    "        store_MI_dict['p_hg'].append(p_val_hg)\n",
    "        store_MI_dict['encoding'].append(1)\n",
    "        store_MI_dict['sub_sess_elec'].append(sel)\n",
    "        store_MI_dict['num_trials'].append(num_trials_elec_encoding)\n",
    "        \n",
    "        store_theta_gamma_PAC_dist['lg_encode'].append(dist_lg)\n",
    "        store_theta_gamma_PAC_dist['hg_encode'].append(dist_hg)\n",
    "\n",
    "\n",
    "        MI_lg, MI_hg, MI_lg_z, MI_hg_z, p_val_lg, p_val_hg, dist_lg, dist_hg = save_MI(theta_gamma_hist_recalled, n_bins)\n",
    "\n",
    "        store_MI_dict['MI_lg'].append(MI_lg)\n",
    "        store_MI_dict['MI_hg'].append(MI_hg)\n",
    "        store_MI_dict['MI_lg_z'].append(MI_lg_z)\n",
    "        store_MI_dict['MI_hg_z'].append(MI_hg_z)\n",
    "        store_MI_dict['p_lg'].append(p_val_lg)\n",
    "        store_MI_dict['p_hg'].append(p_val_hg)\n",
    "        store_MI_dict['encoding'].append(0)\n",
    "        store_MI_dict['sub_sess_elec'].append(sel)\n",
    "        store_MI_dict['num_trials'].append(num_trials_elec_recalled)\n",
    "        \n",
    "        store_theta_gamma_PAC_dist['lg_recall'].append(dist_lg)\n",
    "        store_theta_gamma_PAC_dist['hg_recall'].append(dist_hg)\n",
    "\n",
    "        jsd_lg, jsd_hg, p_val_lg, p_val_hg, jsd_lg_z, jsd_hg_z, jsd_lg_permuted, jsd_hg_permuted = save_JSD(theta_gamma_hist_encoding, theta_gamma_hist_recalled)\n",
    "\n",
    "        store_JSD_dict['jsd_lg'].append(jsd_lg)\n",
    "        store_JSD_dict['jsd_hg'].append(jsd_hg)\n",
    "        store_JSD_dict['jsd_lg_z'].append(jsd_lg_z)\n",
    "        store_JSD_dict['jsd_hg_z'].append(jsd_hg_z)\n",
    "        store_JSD_dict['p_lg'].append(p_val_lg)\n",
    "        store_JSD_dict['p_hg'].append(p_val_hg)\n",
    "        store_JSD_dict['jsd_lg_permuted'].append(jsd_lg_permuted)\n",
    "        store_JSD_dict['jsd_hg_permuted'].append(jsd_hg_permuted)\n",
    "        store_JSD_dict['sub_sess_elec'].append(sel)\n",
    "        store_JSD_dict['num_trials'].append([num_trials_elec_encoding, num_trials_elec_recalled])\n",
    "\n",
    "        np.savez(f'{savePath}MI_{behav_mode}_train', **store_MI_dict)\n",
    "        np.savez(f'{savePath}JSD_{behav_mode}_train', **store_JSD_dict)\n",
    "        np.savez(f'{savePath}dist_{behav_mode}_train', **store_theta_gamma_PAC_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_trials_encode = dict(np.load('/home1/efeghhi/ripple_memory/analysis_code/pac_analyses/updated_data/dd_trials_encoding.npz'))\n",
    "\n",
    "dd_trials_recalled = dict(np.load('/home1/efeghhi/ripple_memory/analysis_code/pac_analyses/updated_data/dd_trials_recall.npz'))\n",
    "\n",
    "correct_idxs = np.argwhere(dd_trials_encode['correct']==1)\n",
    "el_encode = dd_trials_encode['elec_labels'][correct_idxs]\n",
    "elec_intersect = np.intersect1d(dd_trials_recalled['elec_labels'], el_encode)\n",
    "for elec in elec_intersect:\n",
    "    nte = np.argwhere(el_encode==elec).shape[0]\n",
    "    ntr = np.argwhere(dd_trials_recalled['elec_labels']==elec).shape[0]\n",
    "    if nte != ntr:\n",
    "        print(nte, ntr, elec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 second data\n",
      "Loading 1 second data\n",
      "Electrode: R1065J-0_LE2-LE3\n",
      "63 63\n",
      "ENCODING\n",
      "Trial 0 out 63\n",
      "Trial 20 out 63\n",
      "Trial 40 out 63\n",
      "Trial 60 out 63\n",
      "RECALLED\n",
      "Trial 0 out 63\n",
      "Trial 20 out 63\n",
      "Trial 40 out 63\n",
      "Trial 60 out 63\n",
      "(18,) (3, 18)\n"
     ]
    }
   ],
   "source": [
    "MI, JSD, dist = save_MI_JSD(2, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python env1 eb",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
