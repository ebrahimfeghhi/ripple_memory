{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# examining data files in source\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from general import *\n",
    "from SWRmodule import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to detail the process used for the ripple analysis.\n",
    "\n",
    "For each session, we record brain activity for a certain number of trials (words). Brain activity is recorded using electrodes across various brain regions. The data for each brain region is saved separately.\n",
    "\n",
    "Hippocampal (HPC) ripples are stored in an array of the following shape: (num_trials x num_electrodes_hpc) x num_timesteps. Here, num_trials is the number of trials, num_electrodes is the number of electrodes in that brain region, and num_timesteps is the number of timesteps that neural data was recorded for.\n",
    "\n",
    "Let's load the HPC data from one session and see how this checks out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ripple array shape: (840, 1500)\n",
      "Electrode regions: ['left sub', 'left ca1', 'left ca1', 'left sub', 'left ca1', 'left dg', 'left ca1']\n",
      "Trials recorded from each electrode: [120. 120. 120. 120. 120. 120. 120.]\n"
     ]
    }
   ],
   "source": [
    "session_events_hpc = pd.DataFrame()\n",
    "ripple_array_hpc = []\n",
    "sub_sess_names_hpc = []\n",
    "sub_names_hpc = []\n",
    "trial_nums_hpc = []\n",
    "elec_ripple_rate_array_hpc = []\n",
    "\n",
    "fn_hpc = '/scratch/john/SWR_scratch/ENCODING/SWR_catFR1_R1015J_0_HPC_encoding_soz_in_hamming.p'\n",
    "with open(fn_hpc,'rb') as f:\n",
    "    dat = pickle.load(f)\n",
    "    session_events_hpc = session_events_hpc.append(dat['session_events'])\n",
    "    ripple_array_hpc = superVstack(ripple_array_hpc,dat['ripple_array'])\n",
    "    sub_sess_names_hpc.extend(dat['sub_sess_names'])\n",
    "    sub_names_hpc.extend(dat['sub_names'])\n",
    "    trial_nums_hpc = np.append(trial_nums_hpc,dat['trial_nums'])\n",
    "    elec_ripple_rate_array_hpc.extend(dat['elec_ripple_rate_array'])\n",
    "    regions_hpc = dat['HPC_names']\n",
    "    \n",
    "print(f\"Ripple array shape: {ripple_array_hpc.shape}\")\n",
    "print(f\"Electrode regions: {regions_hpc}\")\n",
    "print(f\"Trials recorded from each electrode: {trial_nums_hpc}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for this given session, the participant encoded 120 words. While doing so, brain activity was recorded from 7 different subregions in HPC. That equates to a total of 7*120, or 840 trials of data.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we're interested in analyzing amygdala (AMY) high-frequency activity data when a ripple happens in the CA1 region of HPC. Let's load the AMY data first to get started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ripple array shape: (240, 1500)\n",
      "Electrode regions: ['left amy', 'left amy']\n",
      "Trials recorded from each electrode: [120. 120.]\n"
     ]
    }
   ],
   "source": [
    "session_events_amy = pd.DataFrame()\n",
    "ripple_array_amy = []\n",
    "sub_sess_names_amy = []\n",
    "sub_names_amy = []\n",
    "trial_nums_amy = []\n",
    "elec_ripple_rate_array_amy = []\n",
    "\n",
    "fn_amy = '/scratch/john/SWR_scratch/ENCODING/SWR_catFR1_R1015J_0_AMY_encoding_soz_in_hamming.p'\n",
    "with open(fn_amy,'rb') as f:\n",
    "    dat = pickle.load(f)\n",
    "    session_events_amy = session_events_amy.append(dat['session_events'])\n",
    "    ripple_array_amy = superVstack(ripple_array_amy,dat['ripple_array'])\n",
    "    sub_sess_names_amy.extend(dat['sub_sess_names'])\n",
    "    sub_names_amy.extend(dat['sub_names'])\n",
    "    trial_nums_amy = np.append(trial_nums_amy,dat['trial_nums'])\n",
    "    elec_ripple_rate_array_amy.extend(dat['elec_ripple_rate_array']) \n",
    "    regions_amy = dat['HPC_names']\n",
    "    \n",
    "print(f\"Ripple array shape: {ripple_array_amy.shape}\")\n",
    "print(f\"Electrode regions: {regions_amy}\")\n",
    "print(f\"Trials recorded from each electrode: {trial_nums_amy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that AMY also has a ripple array, but we're not interested in this because we want to condition on CA1 ripples from the same hemisphere. Let's take only CA1 ripples in the next cell, and separate them based on the hemisphere they are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA1 ripple array left hemisphere shape: (4, 120, 1500)\n"
     ]
    }
   ],
   "source": [
    "hpc_subregions_selected = ['ca1'] # only want ripples from this region of hpc \n",
    "\n",
    "# loop through hpc regions\n",
    "# store ripples from the selected\n",
    "left_hemi_data = []\n",
    "right_hemi_data = []\n",
    "trialStart = 0\n",
    "for region, trials in zip(regions_hpc, trial_nums_hpc):\n",
    "    trials = int(trials)\n",
    "    for sb in hpc_subregions_selected:\n",
    "        if f'left {sb}' in region: \n",
    "            left_hemi_data.append(ripple_array_hpc[trialStart:trialStart+trials])\n",
    "        if f'right {sb}' in region: \n",
    "            right_hemi_data.append(ripple_array_hpc[trialStart:trialStart+trials])\n",
    "        \n",
    "        \n",
    "print(f\"CA1 ripple array left hemisphere shape: {np.stack(left_hemi_data).shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, for the left hemisphere, we have an array of shape num_electrodes x num_trials x num_timesteps. Here, num_electrodes is the number of electrodes from selected subregions from that hemisphere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ripples_hpc(nonhpc_trialnums, nonhpc_regions, hpc_trialnums, hpc_regions, ripple_array_hpc, regions_selected):\n",
    "\n",
    "    \n",
    "    timesteps = ripple_array_hpc.shape[1]\n",
    "    num_trials = np.sum(nonhpc_trialnums)\n",
    "\n",
    "    # Step 1: Separate hpc right and left ripples\n",
    "    left_hemi_data = []\n",
    "    right_hemi_data = []\n",
    "    trialStart = 0\n",
    "    for region, trials in zip(hpc_regions, hpc_trialnums):\n",
    "        trials = int(trials)\n",
    "        for rs in regions_selected:\n",
    "            if f'right {rs}' in region: \n",
    "                right_hemi_data.append(ripple_array_hpc[trialStart:trialStart+trials])\n",
    "            if f'left {rs}' in region: \n",
    "                left_hemi_data.append(ripple_array_hpc[trialStart:trialStart+trials])\n",
    "        trialStart += trials \n",
    "\n",
    "    if len(right_hemi_data) > 0:\n",
    "        rhd_np = np.clip(np.sum(np.stack(right_hemi_data),axis=0), a_min=0, a_max=1)\n",
    "    else:\n",
    "        rhd_np = np.zeros_like((trials, timesteps))\n",
    "    if len(left_hemi_data) > 0:\n",
    "        lhd_np = np.clip(np.sum(np.stack(left_hemi_data),axis=0), a_min=0, a_max=1)\n",
    "    else:\n",
    "        lhd_np = np.zeros_like((trials, timesteps))\n",
    "\n",
    "\n",
    "    ripples_hpc_nonhpcshape = np.zeros((int(num_trials), timesteps))\n",
    "\n",
    "    trialStart = 0\n",
    "    for region, trials in zip(nonhpc_regions, nonhpc_trialnums):\n",
    "        trials = int(trials)\n",
    "        \n",
    "        if 'right' in region:\n",
    "            ripples_hpc_nonhpcshape[trialStart:trialStart+trials] = rhd_np\n",
    "        if 'left' in region:\n",
    "            ripples_hpc_nonhpcshape[trialStart:trialStart+trials] = lhd_np\n",
    "\n",
    "        trialStart += trials \n",
    "\n",
    "    return ripples_hpc_nonhpcshape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripples_hpc_amyshape = ripples_hpc(trial_nums_amy, regions_amy,\n",
    "                                 trial_nums_hpc, regions_hpc, ripple_array_hpc, ['ca1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.sum(ripples_hpc_amyshape, axis=1)==0, x>=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e8f5d2e57eff70edb3fd5a3e06f404907a0b2260d7037965ce98bfcad4ff40e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
