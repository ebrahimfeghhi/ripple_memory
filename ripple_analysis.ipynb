{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd; pd.set_option('display.max_columns', 30); pd.set_option('display.max_rows', 100)\n",
    "import numpy as np\n",
    "from cmlreaders import CMLReader, get_data_index\n",
    "from ptsa.data.filters import ButterworthFilter, ResampleFilter, MorletWaveletFilter\n",
    "import xarray as xarray\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import *\n",
    "from copy import copy\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "plt.rcParams['pdf.fonttype'] = 42; plt.rcParams['ps.fonttype'] = 42 # fix fonts for Illustrator\n",
    "sys.path.append('/home1/john/johnModules')\n",
    "from brain_labels import HPC_labels, ENT_labels, PHC_labels, temporal_lobe_labels,\\\n",
    "                         MFG_labels, IFG_labels, nonHPC_MTL_labels\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from general import *\n",
    "from SWRmodule import *\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ripple_analysis():\n",
    "\n",
    "    def __init__(self, exp, df, ripple_bin_start_end=[100,1700], pre_encoding_time=-700, encoding_time=2300, bin_size=100,\n",
    "                            smoothing_triangle=5, samples=100):\n",
    "\n",
    "        self.exp = exp\n",
    "        self.df = df \n",
    "        self.ripple_bin_start_end = ripple_bin_start_end\n",
    "        self.pre_encoding_time = pre_encoding_time\n",
    "        self.encoding_time = encoding_time\n",
    "        self.bin_size = bin_size\n",
    "        self.smoothing_triangle = smoothing_triangle\n",
    "        self.samples = samples \n",
    "\n",
    "    def remove_subject_sessions(self):\n",
    "        \n",
    "        # 575 FR sessions. first 18 of don't load so skip those \n",
    "        exp_df = self.df[self.df.experiment==self.exp]\n",
    "        if self.exp == 'FR1':\n",
    "            exp_df = exp_df[\n",
    "                            ((df.subject!='R1015J') | (df.session!=0)) & \n",
    "                            ((df.subject!='R1063C') | (df.session!=1)) & \n",
    "                            ((df.subject!='R1093J') | (~df.session.isin([1,2]))) &\n",
    "                            ((df.subject!='R1100D') | (~df.session.isin([0,1,2]))) &\n",
    "                            ((df.subject!='R1120E') | (df.session!=0)) &\n",
    "                            ((df.subject!='R1122E') | (df.session!=2)) &\n",
    "                            ((df.subject!='R1154D') | (df.session!=0)) &\n",
    "                            ((df.subject!='R1186P') | (df.session!=0)) &\n",
    "                            ((df.subject!='R1201P') | (~df.session.isin([0,1]))) &\n",
    "                            ((df.subject!='R1216E') | (~df.session.isin([0,1,2]))) &\n",
    "                            ((df.subject!='R1277J') | (df.session!=0)) &\n",
    "                            ((df.subject!='R1413D') | (df.session!=0)) & \n",
    "                            ((df.subject!='R1123C') | (df.session!=2)) & # artifacts that bleed through channels (see SWR FR1 prob sessions ppt)\n",
    "                            ((df.subject!='R1151E') | (~df.session.isin([1,2]))) & # more bleed-through artifacts (see same ppt)\n",
    "                            ((df.subject!='R1275D') | (df.session!=3))  # 3rd session an actual repeat of 2nd session (Paul should have removed from database by now)\n",
    "            #                 (df.subject!='R1065J') # sub with 9000 trials\n",
    "                        ] \n",
    "        elif self.exp == 'catFR1': \n",
    "            exp_df = exp_df[\n",
    "                            ((df.subject!='R1044J') | (df.session!=0)) & # too few trials to do pg pairwise corr\n",
    "                            ((df.subject!='R1491T') | (~df.session.isin([1,3,5]))) & # too few trials to do pg pairwise corr\n",
    "                            ((df.subject!='R1486J') | (~df.session.isin([4,5,6,7]))) & # repeated data...will be removed at some point... @@\n",
    "                            ((df.subject!='R1501J') | (~df.session.isin([0,1,2,3,4,5]))) & # these weren't catFR1 (and they don't load right anyway)\n",
    "                            ((df.subject!='R1235E') | (df.session!=0)) & # split EEG filenames error...documented on Asana\n",
    "                            ((df.subject!='R1310J') | (df.session!=1)) & # session 1 is just a repeat of session 0\n",
    "                            ((df.subject!='R1239E') | (df.session!=0)) # some correlated noise (can see in catFR1 problem sessions ppt)\n",
    "            ]\n",
    "        elif self.exp == 'RepFR1':\n",
    "            exp_df = exp_df[\n",
    "                            (df.subject!='R1564J') # clearly something wrong with these EEG when looking at ripple raster\n",
    "                            ]\n",
    "        # exp_df = exp_df[257:] # for catFR1 this is R1385E-onwwards\n",
    "        # exp_df = exp_df[472:] # for FR1 this is R1385E-onwwards\n",
    "        # exp_df = exp_df[4:7]\n",
    "        self.exp_df = exp_df\n",
    "\n",
    "    def load_data_from_cluster(self, selected_period, region_name='HPC', filter_type='hamming',\n",
    "    sub_selection='first_half', remove_soz_ictal=0, recall_type_switch=0):\n",
    "\n",
    "        '''\n",
    "        :param str selected_period: input one of the following options\n",
    "            'surrounding_recall': aligned to time of free recall \n",
    "            'whole_retrieval': aligned to beginning of retrieval period (beep_off)\n",
    "            'encoding': aligned to word_on\n",
    "            'whole_encoding': aligned to 1st word of each encoding period and ends 29.7 s later (average time for 12 words to be shown)\n",
    "                       NOTE: this analysis is in SWRanalysis-encoding.ipynb now\n",
    "            'math': aligned to math problem on\n",
    "            'math_retrieval': aligned to math problem key-in time\n",
    "        :param str region_name: input can be ENT, HPC, HPC_ENT ENT, HPC, PHC, TEMPORALLOBE, IFG, MFG, ENTPHC, AMY\n",
    "        :param str remove_soz_ictal: input 0 for nothing, 1 for remove SOZ, 2 for keep ONLY SOZ ###\n",
    "        :param str filter_type: input can be butter/hamming/hamming125200/tried hamming140250 for math\n",
    "        :param str sub_selection: input can be second_half (remaining 60%), whole , first_half (first 40%), works for FR1 and catFR1\n",
    "\n",
    "        '''\n",
    "\n",
    "        self.filter_type = filter_type\n",
    "\n",
    "        recall_minimum = 2000 # used if recall_type_switch = 3\n",
    "\n",
    "        # get strings for path name for save and loading cluster data\n",
    "        if recall_type_switch in [0,4,6,8]:\n",
    "            # for these I'm using all trials, but selecting for which recall after the fact\n",
    "            soz_label,recall_selection_name,subfolder = getSWRpathInfo(remove_soz_ictal,0,selected_period, recall_minimum)\n",
    "        else: # these others I haven't set up indexing (see >line 100 in this cell)\n",
    "            soz_label,recall_selection_name,subfolder = getSWRpathInfo(remove_soz_ictal,recall_type_switch,selected_period, recall_minimum)\n",
    "            \n",
    "        ripple_array = []; HFA_array = []\n",
    "        trial_nums = []; encoded_word_key_array = []\n",
    "        HPC_names = []; sub_sess_names = []\n",
    "        region_electrode_ct = []; sub_names = []\n",
    "        trial_by_trial_correlation = []; elec_ripple_rate_array = []\n",
    "        elec_by_elec_correlation = []; fr_array = []\n",
    "        list_num_key = []\n",
    "\n",
    "        serialpos_array = []; list_recall_num_array = []; # ~~~\n",
    "        rectime_array = []; recall_before_intrusion_array = []\n",
    "        recall_position_array = []; session_events = pd.DataFrame()\n",
    "\n",
    "        electrode_labels = []; channel_coords = []; channel_nums = []\n",
    "\n",
    "        analysis_df = getSplitDF(self.exp_df,sub_selection, self.exp)\n",
    "\n",
    "        for row in analysis_df.itertuples(): #analysis_df.itertuples(): #sub_df.itertuples():  \n",
    "            try:\n",
    "                sub = row.subject; session = row.session; exp = row.experiment\n",
    "\n",
    "                path_name = '/scratch/john/SWR_scratch/'+subfolder\n",
    "                fn = os.path.join(path_name,\n",
    "                    'SWR_'+exp+'_'+sub+'_'+str(session)+'_'+region_name+'_'+selected_period+recall_selection_name+\n",
    "                                '_'+soz_label+'_'+filter_type+'.p') #'-NOCUTOFFS.p') #'_no_param_removal.p')   #'.p') #+'.intrusions.p') # +'.-wrong.p') (for wrong math)\n",
    "                                # -NOCUTOFFS for Vaz filter for Norman/Staresina comparison\n",
    "                with open(fn,'rb') as f:\n",
    "                    dat = pickle.load(f)\n",
    "                    ripple_array = superVstack(ripple_array,dat['ripple_array'])\n",
    "                    HFA_array = superVstack(HFA_array,dat['HFA_array'])\n",
    "                    region_electrode_ct.append(dat['region_electrode_ct'])\n",
    "                    encoded_word_key_array.extend(dat['encoded_word_key_array'])\n",
    "                    HPC_names.extend(dat['HPC_names'])\n",
    "                    sub_sess_names.extend(dat['sub_sess_names'])\n",
    "                    sub_names.extend(dat['sub_names'])\n",
    "                    trial_nums = np.append(trial_nums,dat['trial_nums'])\n",
    "                    trial_by_trial_correlation.extend(dat['trial_by_trial_correlation']) # one value for each electrode for this session\n",
    "                    elec_by_elec_correlation = np.append(elec_by_elec_correlation,dat['elec_by_elec_correlation'])\n",
    "                    elec_ripple_rate_array.extend(dat['elec_ripple_rate_array']) # ripple rate by electrode so append\n",
    "                    #,'total_recalls':total_recalls, 'kept_recalls':kept_recalls}, f)\n",
    "                    if selected_period == 'whole_retrieval':\n",
    "                        if np.shape(dat['fr_array'])[0]!=np.shape(dat['ripple_array'])[0]:\n",
    "                            print(sub+str(session))\n",
    "                        fr_array = superVstack(fr_array,dat['fr_array'])\n",
    "                    elif selected_period == 'encoding':\n",
    "                        serialpos_array.extend(dat['serialpos_array'])\n",
    "                        session_events = session_events.append(dat['session_events']) # doesn't append in place \n",
    "                    elif selected_period == 'surrounding_recall': # ~~~\n",
    "                        serialpos_array.extend(dat['serialpos_array']); list_recall_num_array.extend(dat['list_recall_num_array']); # ~~\n",
    "                        rectime_array.extend(dat['rectime_array']); recall_before_intrusion_array.extend(dat['recall_before_intrusion_array'])\n",
    "                        recall_position_array.extend(dat['recall_position_array'])\n",
    "                                    \n",
    "                    elif (selected_period == 'math') | (selected_period == 'math_retrieval'):\n",
    "                        rectime_array.extend(dat['rectime_array'])\n",
    "                        recall_position_array.extend(dat['recall_position_array']); list_recall_num_array.extend(dat['list_recall_num_array'])\n",
    "                    elif selected_period == 'whole_encoding':\n",
    "                        serialpos_array.extend(dat['serialpos_array']); recall_position_array.extend(dat['recall_position_array'])\n",
    "                        list_recall_num_array.extend(dat['list_recall_num_array']); \n",
    "\n",
    "                    electrode_labels.extend(dat['electrode_labels'])\n",
    "                    channel_coords.extend(dat['channel_coords'])\n",
    "                    channel_nums.extend(dat['channel_nums'])\n",
    "                    list_num_key.extend(dat['list_num_key'])\n",
    "                    \n",
    "            except Exception as e:\n",
    "                LogDFExceptionLine(row, e, 'ClusterLoadSWR_log.txt')  \n",
    "        print('**Done reading data**')\n",
    "                \n",
    "        ## loading *all* the recalls with 0, but if it's 4 or 6 load just those trials\n",
    "\n",
    "        # trying new method of loading...translate these to ripple_array length dependent on recall_type_switch \n",
    "        # (this way I can always load from recall_type_switch = 0)\n",
    "\n",
    "        subject_name_array,session_name_array,electrode_array,channel_coords_array,channel_nums_array = getSubSessPredictorsWithChannelNums(\n",
    "                sub_names,sub_sess_names,trial_nums,electrode_labels,channel_coords,channel_nums)\n",
    "\n",
    "        if selected_period == 'surrounding_recall':\n",
    "            if recall_type_switch == 4:\n",
    "                temp_recall_idxs = np.array(recall_position_array)==1\n",
    "            elif recall_type_switch == 6:\n",
    "                temp_recall_idxs = np.array(recall_position_array)>1\n",
    "            elif recall_type_switch == 8:\n",
    "                temp_recall_idxs = np.array(recall_position_array)==2\n",
    "            else:\n",
    "                temp_recall_idxs = np.array(recall_position_array)>=0\n",
    "            self.serialpos_array = np.array(self.serialpos_array)[temp_recall_idxs]\n",
    "            recall_before_intrusion_array = np.array(recall_before_intrusion_array)[temp_recall_idxs]\n",
    "            self.list_num_key = np.array(list_num_key)[temp_recall_idxs]\n",
    "        elif (selected_period == 'math') | (selected_period == 'math_retrieval'):\n",
    "            temp_recall_idxs = np.array(recall_position_array)>=0 # just keep them all for math\n",
    "            encoded_word_key_array.extend(dat['encoded_word_key_array'])\n",
    "        elif selected_period == 'whole_encoding':\n",
    "            temp_recall_idxs = np.array(list_recall_num_array)>=0 # just keep them all\n",
    "        elif selected_period == 'encoding':\n",
    "            temp_recall_idxs = np.ones(len(session_name_array))==1 # just keep them all\n",
    "            session_events = session_events[temp_recall_idxs]\n",
    "            \n",
    "            # spread out encoded_word_key too so I know which words were correct\n",
    "            self.word_correct_array = []\n",
    "            for sess_elec in encoded_word_key_array:\n",
    "                self.word_correct_array.append(sess_elec)\n",
    "            self.word_correct_array = np.array(self.word_correct_array)\n",
    "            self.word_correct_array[self.word_correct_array>0] = 1 # 1s and 2s are corrects\n",
    "            \n",
    "        self.subject_name_array = np.array(subject_name_array)[temp_recall_idxs]\n",
    "        self.session_name_array = np.array(session_name_array)[temp_recall_idxs]\n",
    "        self.electrode_array = np.array(electrode_array)[temp_recall_idxs]\n",
    "        self.channel_coords_array = np.array(channel_coords_array)[temp_recall_idxs]\n",
    "        self.channel_nums_array = np.array(channel_nums_array)[temp_recall_idxs]\n",
    "        self.ripple_array = np.array(ripple_array)[temp_recall_idxs]\n",
    "\n",
    "        print(f\"HFA_array shape before {len(HFA_array)}\")\n",
    "\n",
    "        \n",
    "        self.HFA_array = np.array(HFA_array)[temp_recall_idxs]\n",
    "\n",
    "\n",
    "        if exp == 'surrounding_recall':\n",
    "            self.rectime_array = np.array(rectime_array)[temp_recall_idxs]\n",
    "            self.list_recall_num_array = np.array(list_recall_num_array)[temp_recall_idxs]\n",
    "            self.recall_position_array = np.array(recall_position_array)[temp_recall_idxs]\n",
    "            \n",
    "        print('**Done translating to ripple_array frame**!!')\n",
    "        print('...')\n",
    "        print('% of all HPC subjects for '+exp)\n",
    "        if exp == 'catFR1':\n",
    "            len(np.unique(sub_names))/136*100 # % HPC subs for catFR1\n",
    "            print('% of HPC recalls for '+exp)\n",
    "            self.ripple_array.shape[0]/50053*100 # % recalls for catFR1\n",
    "        if exp == 'FR1':\n",
    "            len(np.unique(sub_names))/167*100 # % HPC subs for FR1\n",
    "            print('% of HPC recalls for '+exp)\n",
    "            self.ripple_array.shape[0]/60417*100 # % recalls for FR1\n",
    "\n",
    "        region_electrode_ct = np.array(region_electrode_ct)\n",
    "        # print('Number of electrodes in each session: '); region_electrode_ct\n",
    "        print('From '+str(sum(region_electrode_ct>0))+'/'+str(len(region_electrode_ct))+' sessions with >0 '+region_name+' electrodes')\n",
    "        print('Total trials: '+str(int(np.sum(trial_nums))))\n",
    "        print('Unique sessions: '+str(len(np.unique(sub_sess_names))))\n",
    "        print('...from '+str(len(np.unique(subject_name_array)))+' patients')\n",
    "\n",
    "        # some info about regions \n",
    "        sub_elec = [subject_name_array[i]+self.electrode_array[i] for i in range(len(self.electrode_array))]\n",
    "        print('Number of electrodes: '+str(len(np.unique(sub_elec))))\n",
    "\n",
    "        print('Electrode regions X sessions:')\n",
    "        unique_names = np.unique(HPC_names)\n",
    "        for name in unique_names:\n",
    "            num_elecs = sum(np.array([names.find(name) for names in HPC_names])>=0)\n",
    "            print(str(num_elecs)+' for '+name)\n",
    "\n",
    "        self.trial_nums = trial_nums\n",
    "        self.sub_sess_names = sub_sess_names\n",
    "        self.HPC_names = HPC_names\n",
    "        self.recall_before_intrusion_array = recall_before_intrusion_array\n",
    "        self.rectime_array = rectime_array\n",
    "        self.list_recall_num_array = list_recall_num_array\n",
    "        self.temp_recall_idxs = temp_recall_idxs\n",
    "        self.selected_period = selected_period\n",
    "        self.sub_names = sub_names\n",
    "        self.serialpos_array = serialpos_array\n",
    "        self.region_name = region_name \n",
    "\n",
    "\n",
    "    def getStartArray(self, region_selection='ca1', select_subfield=True):\n",
    "\n",
    "        '''\n",
    "        :param str region_selection: can be dg, ca3, dg, ca1, sub, 'ca1, dg\n",
    "        @param select_subfield: bool, set to FALSE for ENT or PHC, only can be TRUE for HPC\n",
    "\n",
    "        '''\n",
    "            \n",
    "        # select for subfield if HPC, EF1208\n",
    "        if select_subfield == True and self.region_name=='HPC':\n",
    "            location_selected = region_selection\n",
    "                # left # right # left hippocampus # right hippocampus # hippocampus\n",
    "                # to see number of each: sum(np.array([names.find('sub') for names in HPC_names])>=0)\n",
    "        else:\n",
    "            location_selected = ''\n",
    "            \n",
    "\n",
    "        ### Use a task condition to select recalls?? ###\n",
    "        ### ...will select first one that's not 0    ###\n",
    "        select_ordinal_position = 0              # select only recalls at given output position. 0 means it's off ##DEPRECATED\n",
    "        select_list_position = 0 #[1,2,3] #[12]  # select only recalls at given position from encoding list. \n",
    "                                                # 0 means it's off. Must be list\n",
    "        select_less_than_rectime = 0             # select only recalls < this number % 5000\n",
    "        select_greater_than_rectime = 0          # select only recalls ≥ this number % 5000\n",
    "        select_lists_with_recalls = 0 # list(np.arange(3,13)) # [1] so this would select ≥4 recalls. Must be list hence the list(arange...)\n",
    "                                                # select only recalls that come from lists with number in this list\n",
    "        select_intrusions_next = 0               # select recalls that lead to intrusions\n",
    "            \n",
    "        if self.filter_type.find('hamming') != -1:\n",
    "            desired_sample_rate = 500.\n",
    "        else:\n",
    "            desired_sample_rate = 1000.\n",
    "        sr = desired_sample_rate # fixed at this value since this is the minimum across data and can always downsample\n",
    "        sr_factor = 1000/desired_sample_rate\n",
    "\n",
    "        print('Total electrodes loaded: '+str(len(self.trial_nums)))\n",
    "        print('from '+str(len(np.unique(self.sub_sess_names)))+' sessions from '+str(len(np.unique(self.sub_names)))+' subjects with trial nums:')\n",
    "        print(self.trial_nums[0:20])\n",
    "        print('Trial sum = '+str(np.sum(self.trial_nums)))\n",
    "        print(self.HPC_names[0:20])\n",
    "        print('Number of sub_sess names: '+str(len(self.sub_sess_names)))\n",
    "\n",
    "\n",
    "        start_array,end_array = getStartEndArrays(self.ripple_array) # get start array\n",
    "        \n",
    "        # if selected an output position\n",
    "        if select_ordinal_position > 0:\n",
    "            if np.min(ordinal_position_array) == 0: # only update this once (so don't have to reload data from files)\n",
    "                ordinal_position_array = np.array(ordinal_position_array)+1 # now 1-indexed\n",
    "            selected_recalls = ordinal_position_array==select_ordinal_position\n",
    "        elif type(select_list_position) == list:\n",
    "            selected_recalls = [sp in select_list_position for sp in self.serialpos_array]\n",
    "        elif select_intrusions_next == 1:\n",
    "            selected_recalls = np.array(self.recall_before_intrusion_array)==True\n",
    "        elif select_less_than_rectime > 0:\n",
    "            selected_recalls = np.array(self.rectime_array)<select_less_than_rectime\n",
    "        elif select_greater_than_rectime > 0:\n",
    "            selected_recalls = np.array(self.rectime_array)>=select_greater_than_rectime\n",
    "        elif type(select_lists_with_recalls) == list:\n",
    "            selected_recalls = [recall in select_lists_with_recalls for recall in self.list_recall_num_array]\n",
    "        else:\n",
    "            selected_recalls = np.ones(len(start_array),dtype=bool)\n",
    "            \n",
    "        # get locations if selected\n",
    "        if select_subfield == True:\n",
    "            # create the full vector of location name predictors\n",
    "            location_names = []\n",
    "            for s in range(len(self.HPC_names)):\n",
    "                new_trials = int(self.trial_nums[s])\n",
    "                location_names.extend(np.tile(self.HPC_names[s],new_trials))  \n",
    "                \n",
    "            # now can get mask of trials in this location\n",
    "            \n",
    "            #first, if there are two locations to combine, sort that out (DG and CA1 in particular)\n",
    "            location_mask = np.zeros(len(location_names))\n",
    "            for s in range(len(location_names)):\n",
    "                if type(location_selected)==list:\n",
    "                    if location_names[s].find(location_selected[0])>=0 or location_names[s].find(location_selected[1])>=0:\n",
    "                        location_mask[s] = True\n",
    "                elif type(location_selected)==str:\n",
    "                    if location_names[s].find(location_selected)>=0:\n",
    "                        location_mask[s] = True\n",
    "        else:\n",
    "            location_mask = np.ones(len(start_array))\n",
    "\n",
    "        # gotta translate this to new frame as well from idxs in load step if selected subfield\n",
    "        if select_subfield == True: \n",
    "            location_mask = location_mask[self.temp_recall_idxs] \n",
    "\n",
    "        # combine location and sorted recalls to get new ripple array:\n",
    "        updated_recalls = (location_mask+selected_recalls)==2\n",
    "\n",
    "        print(len(self.serialpos_array))\n",
    "            \n",
    "        # translate these predictors to vector and select recalls\n",
    "        self.start_array = start_array[updated_recalls]\n",
    "        self.end_array = end_array[updated_recalls] # used for duration calculations\n",
    "        self.subject_name_array = np.array(self.subject_name_array)[updated_recalls]\n",
    "        self.session_name_array = np.array(self.session_name_array)[updated_recalls]\n",
    "        self.electrode_array = np.array(self.electrode_array)[updated_recalls]\n",
    "        self.channel_coords_array = np.array(self.channel_coords_array)[updated_recalls]\n",
    "        self.channel_nums_array = np.array(self.channel_nums_array)[updated_recalls]\n",
    "        # if selected_period in ['surrounding_recall','math','math_retrieval']:\n",
    "        #     list_recall_num_array = list_recall_num_array[updated_recalls] # for subject-level analysis\n",
    "        #     rectime_array = np.array(rectime_array)[updated_recalls]\n",
    "        if self.selected_period == 'surrounding_recall':\n",
    "            self.list_num_key = self.list_num_key[updated_recalls]\n",
    "        if self.selected_period == 'encoding':\n",
    "            self.word_correct_array = self.word_correct_array[updated_recalls]\n",
    "            self.serialpos_array = np.array(self.serialpos_array)[updated_recalls]\n",
    "        #     session_events = session_events[updated_recalls]\n",
    "\n",
    "\n",
    "        print(f\"HFA Array shape: {self.HFA_array.shape}\")\n",
    "        print(f\"Updated recalls shape: {updated_recalls.shape}\")\n",
    "        self.HFA_array = self.HFA_array[updated_recalls,:]\n",
    "        self.ripple_array = self.ripple_array[updated_recalls, :] # EF1208\n",
    "            \n",
    "            \n",
    "        print('Got start_array with '+str(start_array.shape[0])+' trials!')\n",
    "\n",
    "        sub_elec = [self.subject_name_array[i]+self.electrode_array[i] for i in range(len(self.electrode_array))]\n",
    "\n",
    "\n",
    "    def ripple_idxs_func(self):\n",
    "\n",
    "        '''\n",
    "        Returns idxs of ripples and no ripples from ripple_array\n",
    "        '''\n",
    "\n",
    "        start = -700\n",
    "        end = 2300\n",
    "\n",
    "        start_marker = int((self.ripple_bin_start_end[0] - start) / 2.0)\n",
    "        end_marker = int((end - self.ripple_bin_start_end[1]) / 2.0)\n",
    "\n",
    "        # Not sure what to do with 0.5 values right now, so going to remove them.\n",
    "        ripple_array_binary = np.where(self.ripple_array==0.5, 0, self.ripple_array)\n",
    "        print(f\"Unique values in ripple array {np.unique(ripple_array_binary)}\")\n",
    "\n",
    "        # sum across rows to find rows where a ripple occurs\n",
    "        ripple_array_rowsum = np.sum(ripple_array_binary[:, start_marker:-end_marker],axis=1)\n",
    "        ripple_bool = np.where(ripple_array_rowsum==0, False, True) \n",
    "        ripple_idxs = np.squeeze(np.argwhere(ripple_bool==True))\n",
    "        non_ripple_idxs = np.squeeze(np.argwhere(ripple_bool==False))\n",
    "        print(f\"Number of events where a ripple occured {ripple_idxs.shape[0]}\")\n",
    "        print(f\"Number of events with no ripples {non_ripple_idxs.shape[0]}\")\n",
    "\n",
    "        return ripple_idxs, non_ripple_idxs\n",
    "\n",
    "    def plot_SME_HFA(self, mode, title_str, savePath):\n",
    "\n",
    "        '''\n",
    "        :param int mode: 0 for all using all HFA activity, 1 for only ripples, and 2 for only non-ripples \n",
    "        '''\n",
    "        pad = int(np.floor(self.smoothing_triangle/2)) \n",
    "        \n",
    "        if mode == 1: \n",
    "            ripple_idxs, _ = self.ripple_idxs_func()\n",
    "            HFA_array = self.HFA_array[ripple_idxs]\n",
    "            word_correct_array = self.word_correct_array[ripple_idxs]\n",
    "            subject_name_array = self.subject_name_array[ripple_idxs]\n",
    "            session_name_array = self.session_name_array[ripple_idxs]\n",
    "        if mode == 2: \n",
    "            _, non_ripple_idxs = self.ripple_idxs_func()\n",
    "            HFA_array = self.HFA_array[non_ripple_idxs]\n",
    "            word_correct_array = self.word_correct_array[non_ripple_idxs]\n",
    "            subject_name_array = self.subject_name_array[non_ripple_idxs]\n",
    "            session_name_array = self.session_name_array[non_ripple_idxs]\n",
    "        \n",
    "        plot_ME_mean = 1 # 0 for typical PSTH, 1 for ME mean, 2 for average across sub averages\n",
    "        save_plot_data = 0\n",
    "\n",
    "        ytextshift = 0\n",
    "\n",
    "        # set up the PVTH stats parameters here too (for encoding have 30 bins)\n",
    "\n",
    "        psth_start = int(self.pre_encoding_time/self.bin_size)\n",
    "        psth_end = int(self.encoding_time/self.bin_size)\n",
    "        sr_factor = 1 # already at 100 ms resolution with these bins\n",
    "\n",
    "        bin_centers = np.arange(psth_start+0.5,psth_end)\n",
    "        xr = bin_centers #np.arange(psth_start,psth_end,binsize)\n",
    "\n",
    "        # get vectors of encoding list identifier data for forgotten and recalled words\n",
    "        # in encoded_word_key_array, 0 for not recalled, 1 for recalled, 2 for recalled but was an IRI<2 (don't care about that for encoding)\n",
    "        start_array_enc_forgot = HFA_array[word_correct_array==0]\n",
    "        start_array_enc_recalled = HFA_array[word_correct_array==1]\n",
    "\n",
    "        # same for sub and sess\n",
    "        sub_forgot = np.array(subject_name_array)[word_correct_array==0]\n",
    "        sess_forgot = np.array(session_name_array)[word_correct_array==0]\n",
    "        sub_recalled = np.array(subject_name_array)[word_correct_array==1]\n",
    "        sess_recalled = np.array(session_name_array)[word_correct_array==1]\n",
    "\n",
    "        # record min and max value before separating into recalled and not recalled in order to write text\n",
    "        PSTH_all = triangleSmooth(np.mean(HFA_array,0),self.smoothing_triangle)\n",
    "        min_val_PSTH = np.min(PSTH_all)\n",
    "        max_val_PSTH = np.max(PSTH_all)\n",
    "\n",
    "        # for recalled and then forgotten words\n",
    "        for category in range(2):\n",
    "            if category == 0:\n",
    "                temp_start_array = start_array_enc_recalled\n",
    "                sub_name_array = sub_recalled\n",
    "                sess_name_array = sess_recalled\n",
    "                     \n",
    "                # HFA \n",
    "                PSTH = triangleSmooth(np.mean(temp_start_array,0),self.smoothing_triangle)\n",
    "\n",
    "                # for plot\n",
    "                subplots(1,1,figsize=(5,4))\n",
    "                label = 'List words later \\\\textbf{recalled}'\n",
    "                plot_color = (0,0,1)\n",
    "                text(0.05, max_val_PSTH+0.32 ,label,usetex=True,size=16,color=plot_color)\n",
    "                text(0.05, max_val_PSTH+0.24,'Number of trials: '+str(temp_start_array.shape[0]),color=plot_color,size=12)\n",
    "\n",
    "            else:       \n",
    "\n",
    "                temp_start_array = start_array_enc_forgot\n",
    "                sub_name_array = sub_forgot\n",
    "                sess_name_array = sess_forgot\n",
    "                \n",
    "                PSTH = triangleSmooth(np.mean(temp_start_array,0),self.smoothing_triangle)\n",
    "\n",
    "                # for plot\n",
    "                label = 'List words later \\\\textbf{not recalled}'        \n",
    "                plot_color = (0,0,0)\n",
    "                text(0.05,max_val_PSTH+ 0.16,label,usetex=True,size=16,color=plot_color) \n",
    "                text(0.05,max_val_PSTH+0.08,'Number of trials: '+str(temp_start_array.shape[0]),color=plot_color,size=12)\n",
    "           \n",
    "\n",
    "            print('done making binned start_array with shape:')\n",
    "            print(temp_start_array.shape)\n",
    "\n",
    "            # note that output is the net ± distance from mean\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings(\"ignore\")    \n",
    "                mean_plot,SE_plot = getMixedEffectMeanSEs(temp_start_array,sub_name_array,sess_name_array)\n",
    "            print('SEs created!')\n",
    "            \n",
    "            if plot_ME_mean == 1:\n",
    "                PSTH = triangleSmooth(mean_plot,self.smoothing_triangle) # replace PSTH with means from ME model (after smoothing as usual)  \n",
    "            elif plot_ME_mean == 2:\n",
    "                temp_means = []\n",
    "                for sub in np.unique(sub_name_array):\n",
    "                    temp_means = superVstack(temp_means,np.mean(temp_start_array[np.array(sub_name_array)==sub],0))\n",
    "                PSTH = triangleSmooth(np.mean(temp_means,0),self.smoothing_triangle)\n",
    "                SE_sub_level = np.std(temp_means,0)/np.sqrt(len(temp_means))     \n",
    "            \n",
    "            ## plot ##\n",
    "            \n",
    "            xr = bin_centers #np.arange(psth_start,psth_end,binsize)\n",
    "            if pad > 0:\n",
    "                xr = xr[pad:-pad]\n",
    "                binned_start_array = temp_start_array[:,pad:-pad] # remove edge bins    \n",
    "                PSTH = PSTH[pad:-pad]\n",
    "                SE_plot = SE_plot[:,pad:-pad]        \n",
    "            \n",
    "            plot(xr,PSTH,color=plot_color)\n",
    "            fill_between(xr, PSTH-SE_plot[0,:], PSTH+SE_plot[0,:], alpha = 0.3)\n",
    "            xticks(np.arange(self.pre_encoding_time+pad*100,self.encoding_time-pad*100+1,500)/100,\n",
    "                np.arange((self.pre_encoding_time+pad*100)/1000,(self.encoding_time-pad*100)/1000+1,500/1000))\n",
    "            xlabel('Time from word presentation (s)')\n",
    "            ylabel('HFA activity (z-scored)')\n",
    "            title(title_str)\n",
    "            tight_layout()\n",
    "            ax = plt.gca()\n",
    "            ax.set_ylim(min_val_PSTH-.10,max_val_PSTH+.40)\n",
    "            ax.set_xlim(self.pre_encoding_time/100,self.encoding_time/100)\n",
    "            plot([0,0],[ax.get_ylim()[0],ax.get_ylim()[1]],linewidth=1,linestyle='-',color=(0,0,0))\n",
    "            plot([1600,1600],[ax.get_ylim()[0],ax.get_ylim()[1]],linewidth=1,linestyle='--',color=(0.7,0.7,0.7))\n",
    "            \n",
    "            if category == 0:\n",
    "                PSTH_recalled = copy(PSTH)\n",
    "                SE_recalled = copy(SE_plot)\n",
    "            else:\n",
    "                PSTH_forgotten = copy(PSTH)\n",
    "                SE_forgotten = copy(SE_plot)    \n",
    "        a=1\n",
    "        plt.savefig(savePath)\n",
    "        \n",
    "        return temp_start_array, sub_name_array, sess_name_array\n",
    "\n",
    "\n",
    "    def SME_ripple_interaction(self, saveBool, savePath):\n",
    "        \n",
    "        wca = self.word_correct_array\n",
    "        sess_name_array = self.session_name_array\n",
    "        subj_name_array = self.subject_name_array\n",
    "        HFA = self.HFA_array\n",
    "        HFA_time_avg = np.mean(HFA, axis=1)\n",
    "\n",
    "        # ripple_exists array is a binary vector of shape num_events, with 1 indicating presence of a ripple\n",
    "        ripple_idxs, non_ripple_idxs = self.ripple_idxs_func()\n",
    "        ripple_exists = np.zeros_like(wca)\n",
    "        ripple_exists[ripple_idxs] = 1\n",
    "        assert np.sum(ripple_exists) == ripple_idxs.shape[0], print(\"Something is not right.\")\n",
    "\n",
    "        # average over HFA from 400-1100 ms post word onset\n",
    "        encoding_onset = -700\n",
    "        HFA_bins = [(400-encoding_onset)/100, (1100-encoding_onset)/100]\n",
    "        HFA_time_range = np.arange(HFA_bins[0], HFA_bins[1]+1) # 11 to 18, corresponding to 400-1100 ms post word onset\n",
    "        HFA_time_restricted = HFA[:, int(HFA_time_range[0]):int(HFA_time_range[-1])]\n",
    "        HFA_mean = np.mean(HFA_time_restricted,axis=1)\n",
    "\n",
    "        # run mixed effects model \n",
    "        vc = {'session':'0+session'}\n",
    "\n",
    "        SE_df = pd.DataFrame(data={'session':sess_name_array,'subject':subj_name_array,'ripple_exists':ripple_exists, \n",
    "                                    'word_recalled': wca, 'HFA_mean': HFA_mean})\n",
    "        get_bin_CI_model = smf.mixedlm(\"HFA_mean ~ ripple_exists*word_recalled\", SE_df, groups=\"subject\", vc_formula=vc, \n",
    "                                        re_formula='ripple_exists*word_recalled')\n",
    "        bin_model = get_bin_CI_model.fit(reml=True, method='nm',maxiter=2000)\n",
    "\n",
    "        # run OLS model for verification \n",
    "        get_bin_CI_model_ols = smf.ols(\"HFA_mean ~ ripple_exists*word_recalled\", SE_df)\n",
    "        bin_model_ols = get_bin_CI_model_ols.fit()\n",
    "\n",
    "        if saveBool:\n",
    "            bin_model_ols.save(f'updates/{savePath}_ols.pickle')\n",
    "            bin_model.save(f'updates/{savePath}_mem.pickle')\n",
    "\n",
    "        self.save_model_info(bin_model, savePath=f'updates/stats_results/mem_model_SME_{self.region_name}.csv')\n",
    "        self.save_model_info(bin_model_ols, savePath=f'updates/stats_results/OLS_model_SME_{self.region_name}.csv')\n",
    "\n",
    "        return bin_model, bin_model_ols\n",
    "\n",
    "\n",
    "    def save_model_info(self, model, savePath, params=['Intercept', 'ripple_exists', 'word_recalled', \n",
    "                                    'ripple_exists:word_recalled']):\n",
    "        \n",
    "        param_dict = {}\n",
    "        param_dict['name'] = []\n",
    "        param_dict['coef'] = []\n",
    "        param_dict['stderr'] = []\n",
    "        param_dict['pval'] = []\n",
    "        param_dict['tval'] = []\n",
    "\n",
    "        for param in params:\n",
    "\n",
    "            param_dict['name'].append(param)\n",
    "            param_dict['coef'].append(model.params[param])\n",
    "            param_dict['stderr'].append(model.bse[param])\n",
    "            param_dict['pval'].append(model.pvalues[param])\n",
    "            param_dict['tval'].append(model.tvalues[param])\n",
    "\n",
    "        pd.DataFrame(param_dict).to_csv(savePath, index=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/efeghhi/.conda/envs/env1/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R1393T' 'R1461T' 'R1426N' 'R1269E' 'R1334T' 'R1239E' 'R1217T' 'R1303E'\n",
      " 'R1264P' 'R1377M']\n",
      "['R1386T' 'R1493T' 'R1278E' 'R1501J' 'R1477J' 'R1449T' 'R1243T' 'R1293P'\n",
      " 'R1459M' 'R1496T']\n",
      "2023-03-28_13-18-56: DF Exception: Sub: R1147P, Sess: 0, FileNotFoundError, [Errno 2] No such file or directory: '/scratch/john/SWR_scratch/ENCODING/SWR_catFR1_R1147P_0_HPC_encoding_soz_in_hamming.p', file: <ipython-input-79-203f0b8a424b>, line no: 112\n",
      "2023-03-28_13-18-58: DF Exception: Sub: R1269E, Sess: 1, FileNotFoundError, [Errno 2] No such file or directory: '/scratch/john/SWR_scratch/ENCODING/SWR_catFR1_R1269E_1_HPC_encoding_soz_in_hamming.p', file: <ipython-input-79-203f0b8a424b>, line no: 112\n",
      "2023-03-28_13-18-58: DF Exception: Sub: R1269E, Sess: 3, FileNotFoundError, [Errno 2] No such file or directory: '/scratch/john/SWR_scratch/ENCODING/SWR_catFR1_R1269E_3_HPC_encoding_soz_in_hamming.p', file: <ipython-input-79-203f0b8a424b>, line no: 112\n",
      "2023-03-28_13-19-01: DF Exception: Sub: R1354E, Sess: 0, FileNotFoundError, [Errno 2] No such file or directory: '/scratch/john/SWR_scratch/ENCODING/SWR_catFR1_R1354E_0_HPC_encoding_soz_in_hamming.p', file: <ipython-input-79-203f0b8a424b>, line no: 112\n",
      "2023-03-28_13-19-01: DF Exception: Sub: R1361C, Sess: 0, FileNotFoundError, [Errno 2] No such file or directory: '/scratch/john/SWR_scratch/ENCODING/SWR_catFR1_R1361C_0_HPC_encoding_soz_in_hamming.p', file: <ipython-input-79-203f0b8a424b>, line no: 112\n",
      "2023-03-28_13-19-03: DF Exception: Sub: R1426N, Sess: 1, FileNotFoundError, [Errno 2] No such file or directory: '/scratch/john/SWR_scratch/ENCODING/SWR_catFR1_R1426N_1_HPC_encoding_soz_in_hamming.p', file: <ipython-input-79-203f0b8a424b>, line no: 112\n",
      "2023-03-28_13-19-06: DF Exception: Sub: R1463E, Sess: 1, FileNotFoundError, [Errno 2] No such file or directory: '/scratch/john/SWR_scratch/ENCODING/SWR_catFR1_R1463E_1_HPC_encoding_soz_in_hamming.p', file: <ipython-input-79-203f0b8a424b>, line no: 112\n",
      "2023-03-28_13-19-06: DF Exception: Sub: R1465D, Sess: 3, FileNotFoundError, [Errno 2] No such file or directory: '/scratch/john/SWR_scratch/ENCODING/SWR_catFR1_R1465D_3_HPC_encoding_soz_in_hamming.p', file: <ipython-input-79-203f0b8a424b>, line no: 112\n",
      "**Done reading data**\n",
      "HFA_array shape before 88462\n",
      "**Done translating to ripple_array frame**!!\n",
      "...\n",
      "% of all HPC subjects for catFR1\n",
      "% of HPC recalls for catFR1\n",
      "From 90/101 sessions with >0 HPC electrodes\n",
      "Total trials: 88462\n",
      "Unique sessions: 90\n",
      "...from 44 patients\n",
      "Number of electrodes: 204\n",
      "Electrode regions X sessions:\n",
      "66 for  left hippocampus\n",
      "41 for  right hippocampus\n",
      "73 for \"ca1\"\n",
      "42 for \"dg\"\n",
      "10 for \"sub\"\n",
      "57 for left ca1\n",
      "1 for left ca2\n",
      "1 for left ca3\n",
      "46 for left dg\n",
      "83 for left hippocampus\n",
      "7 for left sub\n",
      "28 for right ca1\n",
      "27 for right dg\n",
      "45 for right hippocampus\n",
      "6 for right sub\n"
     ]
    }
   ],
   "source": [
    "# init variables\n",
    "df = get_data_index(\"r1\") # all RAM subjects\n",
    "exp = 'catFR1' # 'FR1' 'catFR1' 'RepFR1'\n",
    "ripple_bin_start_end = [100, 1700]\n",
    "region_name = 'HPC'\n",
    "savePath_SME_ripple_fig = f'updates/figures/ripple_HFA_wr_{region_name}'\n",
    "savePath_SME_noripple_fig = f'updates/figures/no_ripple_HFA_wr_{region_name}'\n",
    "\n",
    "RS = ripple_analysis(exp, df, ripple_bin_start_end)\n",
    "RS.remove_subject_sessions()\n",
    "RS.load_data_from_cluster('encoding', region_name=region_name)\n",
    "#RS.getStartArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in ripple array []\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-c0909d2e6cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtitle_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Ripple {region_name}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtitle_nr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'No ripple {region_name}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtemp_start_array_ripple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_name_array_ripple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess_name_array_ripple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_SME_HFA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavePath_SME_ripple_fig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtemp_start_array_noripple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_name_array_noripple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess_name_array_noripple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_SME_HFA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_nr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavePath_SME_noripple_fig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-52e9f9a981a4>\u001b[0m in \u001b[0;36mplot_SME_HFA\u001b[0;34m(self, mode, title_str, savePath)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mripple_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mripple_idxs_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0mHFA_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHFA_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mripple_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mword_correct_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_correct_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mripple_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-52e9f9a981a4>\u001b[0m in \u001b[0;36mripple_idxs_func\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;31m# sum across rows to find rows where a ripple occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mripple_array_rowsum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mripple_array_binary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_marker\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mend_marker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         \u001b[0mripple_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mripple_array_rowsum\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mripple_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mripple_bool\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "title_r = f'Ripple {region_name}'\n",
    "title_nr = f'No ripple {region_name}'\n",
    "temp_start_array_ripple, sub_name_array_ripple, sess_name_array_ripple = RS.plot_SME_HFA(1, title_r, savePath_SME_ripple_fig)\n",
    "temp_start_array_noripple, sub_name_array_noripple, sess_name_array_noripple = RS.plot_SME_HFA(2, title_nr, savePath_SME_noripple_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in ripple array [0. 1.]\n",
      "Number of events where a ripple occured 11463\n",
      "Number of events with no ripples 21898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/efeghhi/.conda/envs/env1/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2094: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/home1/efeghhi/.conda/envs/env1/lib/python3.7/site-packages/statsmodels/base/model.py:1286: RuntimeWarning: invalid value encountered in sqrt\n",
      "  bse_ = np.sqrt(np.diag(self.cov_params()))\n",
      "/home1/efeghhi/.conda/envs/env1/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/home1/efeghhi/.conda/envs/env1/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/home1/efeghhi/.conda/envs/env1/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1892: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    }
   ],
   "source": [
    "mem_model, ols_model = RS.SME_ripple_interaction(saveBool=False, savePath='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e8f5d2e57eff70edb3fd5a3e06f404907a0b2260d7037965ce98bfcad4ff40e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
